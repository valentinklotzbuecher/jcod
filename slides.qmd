---
title: "Synthetic Control and Synthetic Difference-in-Differences"
subtitle: "A modern, design-first view of panel counterfactuals"
author: "Valentin Klotzbücher"
date: last-modified

# one source → two decks
format:
  revealjs:
    theme: [default, theme-dark.scss]
    slide-number: true
    incremental: true
    toc: false
    center: false
    width: 1280
    height: 720
    format-links: [beamer]
  beamer:
    aspectratio: 169
    include-in-header: beamer-unibas.tex
    fonttheme: professionalfonts
    classoption:
      - "t"  # Top-align content

bibliography: references.bib
csl: the-quarterly-journal-of-economics.csl

execute:
  echo: false
  warning: false
  message: false
---

```{r}
#| label: prep
#| include: false
#| cache: true

# ── Libraries ──
library(dplyr)
library(tidyr)
library(ggplot2)
library(fixest)
library(scpi)
library(lubridate)
set.seed(420)

# ── Simulation: Monthly data ──
hospitals <- c("Basel", "Zurich", "Bern", "Geneva", "Lausanne",
               "St_Gallen", "Luzern", "Aarau", "Winterthur",
               "Fribourg", "Chur", "Bellinzona")

# Monthly sequence: Jan 2012 to Dec 2023
months <- seq(as.Date("2012-01-01"), as.Date("2023-12-01"), by = "month")
T0_date <- as.Date("2018-07-01")  # Treatment starts July 2018
treated_unit <- "Basel"

# Numeric time index for models (months since start)
time_idx <- seq_along(months)
T0 <- which(months == T0_date)
pre_periods <- 1:(T0 - 1)

# Time trend with latent factors + seasonality
time_trend <- tibble(
  month = months,
  t = time_idx,
  # Linear trend (gradual decline)
  lambda = -0.015 * (t - 1),
  # Latent factor 1: smooth business cycle (~4 year period)
  f1 = 1.2 * sin(2 * pi * t / 48),
  # Latent factor 2: policy shock around 2020 (COVID-like)
  f2 = -1.5 * plogis((t - 97) / 3) + 0.8 * plogis((t - 109) / 4),
  # Seasonality (winter peaks for hospital data)
  season = 0.6 * cos(2 * pi * (month(month) - 1) / 12)
)

# Hospital parameters (heterogeneous factor loadings)
hosp_par <- tibble(
  hospital = hospitals,
  alpha_i  = rnorm(length(hospitals), 0, 1.2),
  gamma1_i = rnorm(length(hospitals), 1.0, 0.3),   # loading on f1
  gamma2_i = rnorm(length(hospitals), 1.0, 0.25),  # loading on f2
  season_i = rnorm(length(hospitals), 1.0, 0.2)    # seasonal sensitivity
) %>%
  # Basel has different loadings (violates parallel trends)
  mutate(
    gamma1_i = dplyr::if_else(hospital == treated_unit, gamma1_i + 0.4, gamma1_i),
    gamma2_i = dplyr::if_else(hospital == treated_unit, gamma2_i - 0.3, gamma2_i)
  )

# Panel data
df <- expand_grid(hospital = hospitals, t = time_idx) %>%
  left_join(time_trend, by = "t") %>%
  left_join(hosp_par, by = "hospital") %>%
  mutate(
    treated = (hospital == treated_unit),
    post    = (t >= T0),
    # Potential outcome without treatment
    mu0 = 50 + alpha_i + lambda + gamma1_i * f1 + gamma2_i * f2 + season_i * season,
    # Treatment effect: gradual phase-in over 6 months, then stable at -2.5
    months_post = pmax(0, t - T0 + 1),
    tau = dplyr::if_else(treated & post, -2.5 * pmin(months_post / 6, 1), 0),
    # Observed outcome
    y = mu0 + tau + rnorm(n(), 0, 0.8)
  ) %>%
  select(hospital, month, t, treated, post, y)

# ── TWFE DiD ──
df2 <- df %>%
  mutate(treated_i = as.integer(treated),
         post_i = as.integer(post),
         tp = treated_i * post_i)
m_did <- feols(y ~ tp | hospital + t, data = df2, cluster = "hospital")
att_did <- unname(coef(m_did)["tp"])

# ── scpi SCM ──
post_periods <- T0:max(time_idx)

dat_sc <- scdata(
  df = df, id.var = "hospital", time.var = "t", outcome.var = "y",
  period.pre = pre_periods, period.post = post_periods,
  unit.tr = treated_unit, unit.co = setdiff(hospitals, treated_unit),
  constant = TRUE, verbose = FALSE
)

res_scpi <- scpi(data = dat_sc, w.constr = list(name = "simplex"),
                 sims = 200, e.method = "gaussian", u.missp = TRUE)

# Robust ATT extraction
Y_post_actual <- res_scpi$data$Y.post
Y_post_fit <- res_scpi$est.results$Y.post.fit
att_scpi <- mean(Y_post_actual - Y_post_fit)

# Series for plotting
Y_pre_actual <- res_scpi$data$Y.pre
Y_pre_fit <- res_scpi$est.results$Y.pre.fit
scm_series <- tibble(
  t = c(pre_periods, post_periods),
  real = c(as.numeric(Y_pre_actual), as.numeric(Y_post_actual)),
  synth = c(as.numeric(Y_pre_fit), as.numeric(Y_post_fit))
) %>% left_join(time_trend %>% select(t, month), by = "t")

# ── Comparison table ──
cmp_tbl <- tibble(
  Method = c("TWFE DiD", "SCM (scpi)"),
  ATT = c(att_did, att_scpi)
)

# ── Pre-built plots ──
# Raw panel (use dates for x-axis)
p_raw <- ggplot(df, aes(month, y, group = hospital,
                        colour = dplyr::if_else(treated, "Basel", "Donors"))) +
  geom_line(linewidth = 0.5, alpha = 0.8) +
  geom_vline(xintercept = T0_date, linetype = 2, colour = "red") +
  scale_colour_manual(values = c("Basel" = "steelblue", "Donors" = "grey60")) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
  labs(title = "Simulated monthly panel: Basel (treated) vs donors",
       subtitle = paste0("Vertical line: treatment (", format(T0_date, "%b %Y"), ")"),
       x = NULL, y = "Outcome", colour = NULL) +
  theme_minimal()

# SCM trends (scpi)
scm_plot_df <- scm_series %>%
  pivot_longer(cols = c(real, synth), names_to = "series", values_to = "y")

p_scm_trends <- ggplot(scm_plot_df, aes(month, y, colour = series)) +
  geom_line(linewidth = 0.8) +
  geom_vline(xintercept = T0_date, linetype = 2, colour = "red") +
  scale_colour_manual(values = c("real" = "steelblue", "synth" = "darkorange"),
                      labels = c("real" = "Basel", "synth" = "Synthetic")) +
  scale_x_date(date_breaks = "2 years", date_labels = "%Y") +
  labs(title = "SCM: Basel vs Synthetic Control",
       subtitle = paste0("Vertical line: treatment (", format(T0_date, "%b %Y"), ")"),
       x = NULL, y = "Outcome", colour = NULL) +
  theme_minimal()

# Format treatment date for slides
T0_label <- format(T0_date, "%B %Y")
```

<!-- ═══════════════════════════════════════════════════════════════════════ -->
<!-- SECTION A — Motivation & Literature                                     -->
<!-- ═══════════════════════════════════════════════════════════════════════ -->

## Motivation

**Hospital-level interventions** pose unique causal inference challenges:

- Policy implemented at a single site (e.g., Basel)
- Limited control units, heterogeneous baseline trends
- Need credible **counterfactual trajectory**: what would have happened without the intervention?

::: notes
Classic example: one hospital adopts a new protocol. We observe the outcome afterward, but need a principled comparison group.
:::

---

## Why DiD is uncomfortable

Standard **Difference-in-Differences** assumes:

- Parallel trends: treated and control would evolve identically absent treatment
- With a single treated unit, this is untestable and often implausible
- Heterogeneous responses to common shocks (e.g., pandemic) break the assumption

**Key insight:** We need methods that *construct* a comparison unit rather than assume one exists.

::: notes
DiD works well with many treated/control units and credible parallel trends. With one treated unit, we're often forcing a bad fit.
:::

---

## One estimand, three levers

**Target:** ATT = $\mathbb{E}[Y_{1}^{(1)} - Y_{1}^{(0)} \mid D_1 = 1]$

Three design dimensions distinguish modern panel methods:

| Dimension | What it controls |
|-----------|------------------|
| **Unit weights** | How to weight donor units |
| **Time weights** | How to weight pre-treatment periods |
| **Outcome model** | Whether to model $Y^{(0)}$ directly |

All methods combine these three levers differently.

::: notes
This framework helps organize the zoo of methods. Classical SCM optimizes unit weights only. SDID adds time weights. IFE adds outcome modeling.
:::

---

## Matching → SCM → SDID

| Method | Unit weights | Time weights |
|--------|--------------|--------------|
| DiD | Equal (or propensity) | Equal |
| SCM | Optimized (pre-fit) | Equal |
| SDID | Optimized | Optimized |

**Progression:** From assuming comparability to constructing it.

::: notes
SCM optimizes which donors to use; SDID also optimizes which pre-periods matter most. More flexible = more data-adaptive.
:::

---

## Key papers

Foundational and applied references:

- @Abadie2021SyntheticControls — comprehensive review of SCM
- @CattaneoEtAl2025scpi — inference and prediction intervals
- @AbadieZhao2025SCD — SCM as experimental design
- @Kreif2016ExaminationSCM — health policy applications
- @Bonander2021SCMTutorial — practical tutorial
- @Cunningham2021SyntheticControlChapter — textbook treatment

::: notes
These cover theory, health applications, and practical guidance. The Cunningham chapter is excellent for intuition.
:::

---

<!-- ═══════════════════════════════════════════════════════════════════════ -->
<!-- SECTION B — SCM Core                                                    -->
<!-- ═══════════════════════════════════════════════════════════════════════ -->

## SCM intuition

**Core idea:** Build a *synthetic control* as a weighted combination of donor units.

- Weights chosen to match the treated unit's pre-treatment trajectory
- The synthetic unit serves as the counterfactual
- Treatment effect = observed outcome − synthetic outcome

$$
\widehat{Y}_{1t}^{(0)} = \sum_{j=2}^{J+1} w_j \cdot Y_{jt} \quad \text{where } \sum_j w_j = 1, \; w_j \geq 0
$$

::: notes
We're constructing a "frankenunit" from donors that looks like the treated unit pre-treatment.
:::

---

## SCM objective + weights

Weights minimize pre-treatment prediction error:

$$
\min_{W} \sum_{t < T_0} \left( Y_{1t} - \sum_{j=2}^{J+1} w_j Y_{jt} \right)^2
$$

Subject to:

- $w_j \geq 0$ (no negative weights)
- $\sum_j w_j = 1$ (convex combination)

**Result:** Sparse weights; typically few donors receive positive weight.

::: notes
The optimization is a constrained regression. Sparsity helps interpretability—we can say "synthetic Basel is 60% Zurich + 40% Bern."
:::

---

## Diagnostics workflow

Before trusting SCM estimates:

1. **Pre-fit balance:** Does synthetic match treated pre-treatment?
2. **Weights inspection:** Are weights sensible? Too concentrated?
3. **Placebo tests:** Run SCM on each donor as if treated
4. **Pre-treatment RMSPE:** Large gaps pre-treatment → unreliable post-treatment

::: notes
Diagnostics are essential. A poor pre-fit means the counterfactual is unreliable.
:::

---

<!-- ═══════════════════════════════════════════════════════════════════════ -->
<!-- SECTION C — Modern SCM Family                                           -->
<!-- ═══════════════════════════════════════════════════════════════════════ -->

## Why classical SCM can fail

Limitations of the original method:

- **Overfitting:** Too many predictors relative to pre-periods
- **Interpolation bias:** Treated unit outside convex hull of donors
- **No extrapolation:** Convex weights can't capture factor loadings outside donor range
- **Single factor structure:** May miss complex latent heterogeneity

::: notes
These issues motivate the modern extensions: gsynth, augsynth, sdid, etc.
:::

---

## Generalized SCM / IFE / MC

Modern extensions relax classical SCM assumptions:

| Method | Key idea |
|--------|----------|
| **IFE** (Interactive Fixed Effects) | Estimate latent factors + loadings jointly |
| **MC** (Matrix Completion) | Low-rank imputation of missing counterfactuals |
| **Augmented SCM** | Bias correction via outcome modeling |

All share the intuition: **impute the missing $Y_{1t}^{(0)}$** using structure in the panel.

::: notes
gsynth implements IFE and MC. These are more flexible than classical SCM but require more data.
:::

---

## What scpi buys you

The **scpi** package [@CattaneoEtAl2025scpi] provides:

- **Prediction intervals** — not just point estimates
- **Multiple weight constraints** — simplex, lasso, ridge
- **Staggered adoption** — built-in support for multiple treatment times
- **Covariate adjustment** — integrate auxiliary predictors

**Workflow:** `scdata()` → `scpi()` → `scplot()`

::: notes
scpi is now the canonical implementation. It handles inference properly, unlike older packages.
:::

---

<!-- ═══════════════════════════════════════════════════════════════════════ -->
<!-- SECTION D — Simulation Illustration                                     -->
<!-- ═══════════════════════════════════════════════════════════════════════ -->

## Scope of today

What we cover:

- Intuition behind SCM and modern extensions
- Diagnostics and practical workflow
- Simulation illustration with R

What we leave to the papers:

- Formal inference (permutation tests, conformal inference)
- Covariate adjustment details
- Staggered adoption designs

**Design choices often matter more than estimator choice.**

::: notes
This is a methods overview, not a deep dive into asymptotics.
:::

---

## Simulation design

**Monthly panel with latent factors:**

- 12 Swiss hospitals, Jan 2012 – Dec 2023 (144 months)
- Basel treated at $T_0$ = July 2018
- True ATT = −2.5 (gradual phase-in over 6 months)
- Two latent factors + seasonality; Basel has different loadings

This setup *violates* parallel trends—donors respond differently to common shocks.

::: notes
We deliberately create a scenario where DiD would struggle but SCM methods should recover the effect.
:::

---

## DGP: Latent factors

```{r}
#| label: show-dgp-code
#| echo: true
#| eval: false
#| code-line-numbers: "3-8|10-11"

# Potential outcome without treatment
mu0 = 50 + alpha_i + lambda +
      gamma1_i * f1 +       # business cycle (heterogeneous loading)
      gamma2_i * f2 +       # policy shock (heterogeneous loading)
      season_i * season     # winter peaks

# Treatment effect: gradual phase-in
months_post = pmax(0, t - T0 + 1)
tau = if_else(treated & post,
              -2.5 * pmin(months_post / 6, 1), 0)
```

Basel has different $\gamma_1, \gamma_2$ → parallel trends fail.

---

## Raw panel

```{r}
#| label: show-raw-panel
p_raw
```

::: notes
Notice the heterogeneous trends—this is why parallel trends won't hold.
:::

---

## TWFE DiD estimate

```{r}
#| label: show-did-estimate
cat("TWFE DiD ATT estimate:", round(att_did, 3), "\n")
cat("True ATT: -2.5")
```

Standard two-way fixed effects with treatment indicator.

**Interpretation:** DiD may be biased due to heterogeneous factor loadings.

::: notes
DiD gives a number, but we can't trust it without parallel trends.
:::

---

## scpi: Fitting SCM

```{r}
#| label: show-scpi-code
#| echo: true
#| eval: false
#| code-line-numbers: "1-5|7-9"

# Step 1: Prepare data structure
dat_sc <- scdata(
  df = df, id.var = "hospital", time.var = "t", outcome.var = "y",
  period.pre = pre_periods, period.post = post_periods,
  unit.tr = "Basel", unit.co = setdiff(hospitals, "Basel"))

# Step 2: Estimate with simplex constraints + inference
res_scpi <- scpi(data = dat_sc, w.constr = list(name = "simplex"),
                 sims = 200, e.method = "gaussian")
```

---

## SCM: Basel vs Synthetic Control

```{r}
#| label: show-scm-trends
p_scm_trends
```

```{r}
#| label: show-scm-att
cat("SCM (scpi) ATT:", round(att_scpi, 3))
```

::: notes
The synthetic control tracks Basel well pre-treatment, then diverges post-July 2018.
:::

---

## Imputation family: IFE / MC

**Interactive Fixed Effects (IFE):**
$$Y_{it} = \alpha_i + \gamma_t + \sum_{k=1}^{K} \lambda_{ik} f_{kt} + \varepsilon_{it}$$

Latent factors $f_{kt}$ with unit-specific loadings $\lambda_{ik}$.

**Matrix Completion (MC):**
Low-rank imputation — treat missing $Y_{1t}^{(0)}$ as matrix completion problem.

**Package:** `fect` (successor to `gsynth`) — not run here, but excellent for factor-augmented estimation.

::: notes
These methods model the outcome directly, estimating latent factors from the data. More flexible than SCM but requires stronger assumptions about factor structure.
:::

---

## Hybrid family: SDID / AugSCM

**Synthetic Difference-in-Differences (SDID):**

- SCM-style unit weights + DiD-style time weights
- Reweights both donors and pre-periods
- Package: `synthdid`

**Augmented SCM:**

- SCM + ridge regression bias correction
- Reduces interpolation bias
- Package: `augsynth`

::: notes
These hybrids combine the best of both worlds: data-adaptive weighting with bias correction.
:::

---

## Comparison table

```{r}
#| label: show-comparison
knitr::kable(cmp_tbl, digits = 3, col.names = c("Method", "ATT Estimate"))
```

**True ATT = −2.5**

Both methods recover the treatment effect well; SCM does better when parallel trends fail.

::: notes
DiD can be biased when parallel trends fail. SCM constructs a better comparison.
:::

---

<!-- ═══════════════════════════════════════════════════════════════════════ -->
<!-- SECTION E — Wrap                                                        -->
<!-- ═══════════════════════════════════════════════════════════════════════ -->

## Practical checklist + limitations

**Before using SCM:**

- ☑ Sufficient pre-treatment periods (≥ 5–10)
- ☑ Good donor pool (similar, unaffected units)
- ☑ Treatment timing known and sharp
- ☑ No anticipation effects

**Limitations:**

- Sparse donors → poor synthetic match
- Extrapolation impossible with convex weights
- Inference remains an active research area

::: notes
These are necessary conditions. Violations lead to unreliable estimates.
:::

---

## Takeaways

1. **SCM constructs** a counterfactual rather than assuming parallel trends
2. **Diagnostics are essential:** pre-fit, weights, placebos
3. **Modern extensions** (IFE, MC, SDID) handle complex factor structures
4. **scpi is the canonical package** — use it for inference and prediction intervals
5. **Design matters more than estimator:** clean setting → all methods work; violated assumptions → all struggle

::: notes
The method is only as good as the setting. Focus on design.
:::

---

## SCM as experimental design

@AbadieZhao2025SCD perspective:

- **Design with SCM in mind** — choose treated unit where good donors exist
- **Pre-register the donor pool** — reduces researcher degrees of freedom
- **Balance as design criterion** — not just an estimation property

**Key insight:** SCM works best when the study is designed for it, not retrofitted.

::: notes
This is a shift in thinking: from "how do I analyze this data?" to "how do I design this study so SCM will work?"
:::

---

## Package recommendations

| Use case | Package |
|----------|---------|
| Canonical SCM + inference | `scpi` |
| Factor-augmented (IFE/MC) | `fect` |
| Synthetic DiD | `synthdid` |
| Augmented SCM | `augsynth` |

**Rule of thumb:** Start with `scpi`. Consider alternatives when factor structure is complex or you need hybrid estimators.

::: notes
scpi should be the default. The others are for specialized cases.
:::

---

## References
